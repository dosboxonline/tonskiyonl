WEBVTT

00:06.047 --> 00:08.800
[cryptic music plays]

00:15.598 --> 00:17.100
[music intensifies]

00:24.065 --> 00:26.818
[woman 1] I find AI to be awe-inspiring.

00:28.361 --> 00:31.489
All right, circling up. Good formation.

00:33.116 --> 00:36.703
[woman 1] AI has the potential
to eliminate poverty,

00:36.786 --> 00:38.705
give us new medicines,

00:39.330 --> 00:41.583
and make our world even more peaceful.

00:46.087 --> 00:46.921
[man 1] Nice work.

00:49.883 --> 00:53.428
[woman 1] But there are so many risks
along the way.

00:54.304 --> 00:55.847
[music crescendos]

01:04.773 --> 01:09.611
With AI, we are essentially creating
a non-human intelligence

01:09.694 --> 01:11.863
that is very unpredictable.

01:14.407 --> 01:16.451
As it gets more powerful,

01:16.534 --> 01:19.746
where are the red lines
we're going to draw with AI,

01:19.829 --> 01:22.665
in terms of how we want to use it,
or not use it?

01:25.001 --> 01:28.505
There is no place that is ground zero
for this conversation

01:28.588 --> 01:31.049
more than military applications.

01:34.010 --> 01:38.890
The battlefield has now become
the province of software and hardware.

01:41.059 --> 01:42.936
[man 1] Target has been acquired…

01:43.019 --> 01:44.771
[woman 1] And militaries are racing

01:44.854 --> 01:48.399
to develop AI faster
than their adversaries.

01:48.483 --> 01:49.442
[beeping]

01:49.526 --> 01:50.360
[man 1] I'm dead.

01:50.944 --> 01:52.028
[tense music plays]

01:52.612 --> 01:53.738
[radio chatter]

01:53.822 --> 01:55.782
[woman 1] We're moving towards a world

01:55.865 --> 01:58.326
where not only major militaries,

01:58.409 --> 02:02.997
but non-state actors, private industries,

02:03.081 --> 02:06.042
or even our local police department
down the street

02:06.543 --> 02:10.046
could be able to use these weapons
that can autonomously kill.

02:12.006 --> 02:17.303
Will we cede the decision to take a life
to algorithms, to computer software?

02:18.638 --> 02:21.516
It's one of the most pressing issues
of our time.

02:23.935 --> 02:26.354
And, if not used wisely,

02:26.437 --> 02:30.275
poses a grave risk
to every single person on the planet.

02:31.317 --> 02:32.694
[buzzing]

02:35.905 --> 02:37.407
[music crescendos]

02:40.118 --> 02:42.871
[ominous music plays]

02:46.749 --> 02:48.751
[music crescendos]

02:56.467 --> 02:58.469
[flies buzzing]

03:00.972 --> 03:02.974
[electronic buzzing]

03:17.697 --> 03:19.657
[tense music plays]

03:19.741 --> 03:21.367
[indistinct radio chatter]

03:28.291 --> 03:30.376
[male voice] Good work out there, guys.

03:30.460 --> 03:31.836
[muffled radio chatter]

03:34.839 --> 03:36.841
[music intensifies]

03:37.342 --> 03:39.886
[indistinct radio chatter]

03:42.722 --> 03:43.556
[gunshots]

03:46.226 --> 03:47.227
[gunshot]

03:47.310 --> 03:48.228
[radio chatter]

03:55.109 --> 03:56.569
[laughter]

03:59.906 --> 04:02.200
[tech 1] That's a wider lens
than we had before.

04:02.283 --> 04:03.117
[man 2] Really?

04:03.201 --> 04:05.203
[tech 1] You can see a lot more data.

04:05.286 --> 04:06.287
Very cool.

04:07.538 --> 04:11.167
At Shield AI, we are building an AI pilot

04:11.251 --> 04:14.879
that's taking self-driving,
artificial intelligence technology

04:14.963 --> 04:16.631
and putting it on aircraft.

04:16.714 --> 04:18.800
[cryptic music plays]

04:19.300 --> 04:21.719
When we talk about an AI pilot,

04:21.803 --> 04:25.139
we think about giving an aircraft
a higher level of autonomy.

04:25.223 --> 04:27.850
They will be solving problems
on their own.

04:29.602 --> 04:32.355
Nova is an autonomous quadcopter

04:32.438 --> 04:35.942
that explores buildings
and subterranean structures

04:36.859 --> 04:38.611
ahead of clearance forces

04:38.695 --> 04:41.322
to provide eyes and ears in those spaces.

04:41.906 --> 04:44.534
You can definitely tell
a ton of improvements

04:44.617 --> 04:45.618
since we saw it last.

04:45.702 --> 04:47.870
[tech 2] We're working
on some exploration changes today.

04:47.954 --> 04:50.248
We're working a little
floor-by-floor stuff.

04:50.331 --> 04:53.584
It'll finish one floor, all the rooms,
before going to the second.

04:54.294 --> 04:56.796
-That's awesome.
-We put in some changes recently…

04:56.879 --> 04:58.548
A lot of people often ask me

04:58.631 --> 05:02.468
why artificial intelligence
is an important capability.

05:02.552 --> 05:06.973
And I just think back to the missions
that I was executing.

05:07.056 --> 05:09.058
[dramatic music plays]

05:09.142 --> 05:10.935
Spent seven years in the Navy.

05:11.561 --> 05:15.273
I was a former Navy SEAL
deployed twice to Afghanistan,

05:15.356 --> 05:17.191
once to the Pacific Theater.

05:18.026 --> 05:22.947
In a given day, we might have to clear
150 different compounds or buildings.

05:23.031 --> 05:24.574
[tense music plays]

05:30.997 --> 05:34.250
One of the core capabilities
is close-quarters combat.

05:35.293 --> 05:39.172
Gunfighting at extremely close ranges
inside buildings.

05:39.672 --> 05:40.506
[gunshot]

05:41.466 --> 05:42.967
You are getting shot at.

05:43.468 --> 05:46.471
There are IEDs
potentially inside the building.

05:47.764 --> 05:48.931
[yelling]

05:49.015 --> 05:55.229
It's the most dangerous thing
that any special operations forces member,

05:55.313 --> 05:58.358
any infantry member,
can do in a combat zone.

05:58.441 --> 05:59.275
Bar none.

06:01.152 --> 06:03.154
[somber music plays]

06:12.497 --> 06:16.334
For the rest of my life
I'll be thankful for my time in the Navy.

06:17.168 --> 06:22.423
There are a collection of moments
and memories that, when I think about,

06:22.507 --> 06:24.592
I certainly get emotional.

06:28.346 --> 06:32.725
It is cliché that freedom isn't free,
but I 100% believe it.

06:32.809 --> 06:37.105
[quavers] Um, I've experienced it,
and it takes a lot of sacrifice.

06:38.022 --> 06:38.856
Sorry.

06:41.067 --> 06:44.570
When something bad happens
to one of your teammates,

06:44.654 --> 06:46.864
whether they're hurt or they're killed,

06:46.948 --> 06:49.700
um, it's just a…
It's a really tragic thing.

06:49.784 --> 06:52.912
You know, for me now
in the work that we do,

06:52.995 --> 06:56.582
it's motivating to um… be able to

06:56.666 --> 06:58.835
you know,
reduce the number of times

06:58.918 --> 07:00.336
that ever happens again.

07:03.965 --> 07:06.426
[ominous music plays]

07:07.176 --> 07:08.886
[man 3] In the late 2000s,

07:08.970 --> 07:11.556
there was this awakening
inside the Defense Department

07:11.639 --> 07:15.351
to what you might call
the accidental robotics revolution.

07:15.893 --> 07:19.564
We deployed thousands of air
and ground robots to Iraq and Afghanistan.

07:21.482 --> 07:24.068
[man 4] When I was asked
by the Obama administration

07:24.152 --> 07:26.404
to become the Deputy Secretary of Defense,

07:26.904 --> 07:29.323
the way war was fought…

07:29.407 --> 07:31.117
uh, was definitely changing.

07:32.452 --> 07:36.330
Robots were used
where people would have been used.

07:37.999 --> 07:40.376
[Paul] Early robotics systems
were remote-controlled.

07:40.460 --> 07:45.173
There's a human driving it, steering it,
like you might a remote-controlled car.

07:46.632 --> 07:51.512
[Bob] They first started generally
going after improvised explosive devices,

07:52.013 --> 07:54.849
and if the bomb blew up,
the robot would blow up.

07:57.393 --> 08:00.396
Then you'd say, "That's a bummer.
Okay, get out the other robot."

08:00.480 --> 08:02.190
[tense music plays]

08:02.273 --> 08:05.067
[woman 2] In Afghanistan,
you had the Predator drone,

08:05.151 --> 08:09.739
and it became a very, very useful tool
to conduct airstrikes.

08:13.117 --> 08:16.829
[Paul] Over time, military planners
started to begin to wonder,

08:16.913 --> 08:20.791
"What else could robots be used for?"
And where was this going?

08:20.875 --> 08:24.170
And one of the common themes
was this trend towards greater autonomy.

08:26.506 --> 08:30.635
[woman 2] An autonomous weapon
is one that makes decisions on its own,

08:30.718 --> 08:33.304
with little to no human intervention.

08:33.387 --> 08:37.558
So it has an independent capacity,
and it's self-directed.

08:38.434 --> 08:41.604
And whether it can kill
depends on whether it's armed or not.

08:42.104 --> 08:43.231
[beeping]

08:43.314 --> 08:47.026
[Bob] When you have more and more autonomy
in your entire system,

08:47.109 --> 08:49.779
everything starts to move
at a higher clock speed.

08:51.989 --> 08:56.869
And when you operate
at a faster pace than your adversaries,

08:57.453 --> 09:01.165
that is an extraordinarily
big advantage in battle.

09:03.960 --> 09:06.254
[man 5] What we focus on as it relates
to autonomy

09:07.255 --> 09:09.882
is highly resilient intelligence systems.

09:09.966 --> 09:11.968
[buzzing]

09:12.051 --> 09:15.304
Systems that can read and react
based on their environment,

09:15.805 --> 09:19.642
and make decisions
about how to maneuver in that world.

09:24.981 --> 09:29.151
The facility that we're at today
was originally built as a movie studio

09:29.235 --> 09:30.611
that was converted over

09:30.695 --> 09:34.156
to enable these realistic
military training environments.

09:35.491 --> 09:37.994
[ominous music plays]

09:39.495 --> 09:43.291
We are here to evaluate our AI pilot.

09:44.625 --> 09:49.297
The mission is looking for threats.
It's about clearance forces.

09:49.380 --> 09:52.800
It can make a decision
about how to attack that problem.

09:55.428 --> 09:59.390
[man 6] We call this "the fatal funnel."
You have to come through a doorway.

10:01.726 --> 10:03.311
It's where we're most vulnerable.

10:03.811 --> 10:05.146
This one looks better.

10:07.106 --> 10:10.151
[man 6] The Nova lets us know,
is there a shooter behind that door,

10:10.818 --> 10:12.653
is there a family behind that door?

10:15.114 --> 10:18.451
It'll allow us to make better decisions
and keep people out of harms way.

10:27.293 --> 10:29.128
[tense music plays]

10:47.730 --> 10:49.482
[music intensifies]

10:57.114 --> 10:59.367
[man 7] We use the vision sensors

10:59.450 --> 11:03.162
to be able to get an understanding
of what the environment looks like.

11:04.997 --> 11:06.415
It's a multistory building.

11:07.333 --> 11:08.334
Here's the map.

11:08.417 --> 11:11.671
While I was exploring,
here's what I saw and where I saw them.

11:16.967 --> 11:18.552
[music crescendos]

11:19.929 --> 11:22.098
[Brandon] Person detector. That's sweet.

11:22.181 --> 11:23.808
[tense music continues]

11:23.891 --> 11:27.436
[man 7] One of the other sensors
onboard Nova is a thermal scanner.

11:27.520 --> 11:30.690
If that's 98.6 degrees,
it probably is a human.

11:32.358 --> 11:35.444
People are considered threats
until deemed otherwise.

11:38.906 --> 11:43.244
It is about eliminating the fog of war
to make better decisions.

11:43.327 --> 11:44.620
[music builds]

11:44.704 --> 11:46.539
And when we look to the future,

11:47.039 --> 11:50.710
we're scaling out to build teams
of autonomous aircraft.

11:50.793 --> 11:52.128
[music crescendos]

11:52.211 --> 11:53.671
[low buzzing]

11:53.754 --> 11:55.631
[man 7] With self-driving vehicles,

11:55.715 --> 11:57.466
ultimately the person has said to it,

11:57.550 --> 12:00.386
"I'd like you to go
from point A to point B."

12:00.469 --> 12:02.471
[low buzzing]

12:02.972 --> 12:06.475
Our systems are being asked
not to go from point A to point B,

12:06.559 --> 12:08.477
but to achieve an objective.

12:08.561 --> 12:10.229
[cryptic music plays]

12:10.312 --> 12:13.190
It's more akin to, "I need milk."

12:13.274 --> 12:17.486
And then the robot would have to
figure out what grocery store to go to,

12:17.570 --> 12:20.239
be able to retrieve that milk,
and then bring it back.

12:20.740 --> 12:22.074
And even more so,

12:22.158 --> 12:27.037
it may be more appropriately stated as,
"Keep the refrigerator stocked."

12:27.538 --> 12:29.457
And so, this is a level of intelligence

12:29.540 --> 12:32.168
in terms to figuring out what we need
and how we do it.

12:32.251 --> 12:34.253
And if there is a challenge, or a problem,

12:34.336 --> 12:37.381
or an issue arises,
figure out how to mitigate that.

12:37.465 --> 12:39.467
[cryptic music continues]

12:40.801 --> 12:45.431
[Brandon] When I had made the decision
to leave the Navy, I started thinking,

12:45.514 --> 12:47.558
"Okay. Well, what's next?"

12:47.641 --> 12:49.059
[bell ringing]

12:49.143 --> 12:52.021
I grew up with the Internet.
Saw what it became.

12:53.189 --> 12:55.608
And part of the conclusion
that I had reached was…

12:56.108 --> 12:58.861
AI in 2015

12:58.944 --> 13:02.907
was really where the Internet was in 1991.

13:04.033 --> 13:06.285
And AI was poised to take off

13:06.368 --> 13:09.747
and be one of the most
powerful technologies in the world.

13:11.791 --> 13:16.212
Working with it every single day,
I can see the progress that is being made.

13:19.048 --> 13:22.051
But for a lot of people,
when they think "AI,"

13:22.551 --> 13:25.221
their minds immediately go to Hollywood.

13:25.304 --> 13:27.556
[beeping]

13:28.057 --> 13:29.975
[computer voice] Shall we play a game?

13:30.059 --> 13:35.314
How about Global Thermonuclear War?

13:35.898 --> 13:36.816
Fine.

13:36.899 --> 13:38.234
[dramatic music plays]

13:38.317 --> 13:40.861
[man 8] When people think
of artificial intelligence generally,

13:40.945 --> 13:44.824
they might think of The Terminator.
Or I, Robot.

13:45.574 --> 13:46.700
Deactivate.

13:46.784 --> 13:48.160
What am I?

13:48.244 --> 13:49.620
[man 8] Or The Matrix.

13:51.080 --> 13:53.749
Based on what you see
in the sci-fi movies,

13:53.833 --> 13:57.878
how do you know I'm a human?
I could just be computer generated AI.

13:58.379 --> 14:02.132
Replicants are like any other machine.
They're either a benefit or a hazard.

14:02.675 --> 14:06.095
[Andrew] But there's all sorts
of more primitive AIs,

14:06.178 --> 14:08.097
that are still going to change our lives

14:08.180 --> 14:11.851
well before we reach
the thinking, talking robot stage.

14:12.643 --> 14:15.771
[woman 3] The robots are here.
The robots are making decisions.

14:15.855 --> 14:18.816
The robot revolution has arrived,

14:18.899 --> 14:22.319
it's just that it doesn't look like
what anybody imagined.

14:23.320 --> 14:25.489
[film character] Terminator's
an infiltration unit.

14:25.573 --> 14:26.740
Part man, part machine.

14:27.950 --> 14:31.370
[man 9] We're not talking about
a Terminator-style killer robot.

14:31.871 --> 14:35.958
We're talking about AI
that can do some tasks that humans can do.

14:36.041 --> 14:39.879
But the concern is
whether these systems are reliable.

14:40.462 --> 14:45.426
[reporter 1] New details in last night's
crash involving a self-driving Uber SUV.

14:45.509 --> 14:48.762
The company created
an artificial intelligence chatbot.

14:48.846 --> 14:51.181
She took on a rather racist tone…

14:51.265 --> 14:55.394
[reporter 2] Twenty-six state legislators
falsely identified as criminals.

14:57.438 --> 15:02.026
The question is whether they can handle
the complexities of the real world.

15:02.109 --> 15:03.110
[birds chirping]

15:03.944 --> 15:06.238
[somber music plays]

15:22.212 --> 15:24.423
[man 10] The physical world
is really messy.

15:25.174 --> 15:27.426
There are many things that we don't know,

15:27.968 --> 15:30.763
making it much harder to train AI systems.

15:30.846 --> 15:33.015
[upbeat music plays]

15:33.098 --> 15:36.977
That is where machine learning systems
have started to come in.

15:38.520 --> 15:41.440
[man 11] Machine learning
has been a huge advancement

15:42.024 --> 15:45.611
because it means that we don't have
to teach computers everything.

15:45.694 --> 15:47.821
[music intensifies]

15:47.905 --> 15:52.409
You actually give a computer
millions of pieces of information,

15:52.493 --> 15:54.453
and the machine begins to learn.

15:55.245 --> 15:57.289
And that could be applied to anything.

16:00.250 --> 16:02.962
[Pulkit] Our Robot Dog project,
we are trying to show

16:03.045 --> 16:09.009
that our dog can walk across
many, many diverse terrains.

16:10.052 --> 16:14.098
Humans have evolved
over billions of years to walk,

16:14.932 --> 16:20.688
but there's a lot of intelligence
in adapting to these different terrains.

16:21.939 --> 16:24.316
The question remains
for robotic systems is,

16:24.400 --> 16:27.069
could they also adapt
like animals and humans?

16:30.656 --> 16:32.157
[music crescendos]

16:33.826 --> 16:35.869
[cryptic music plays]

16:35.953 --> 16:37.413
With machine learning,

16:37.496 --> 16:40.582
we collect lots and lots
of data in simulation.

16:42.668 --> 16:45.838
A simulation is a digital twin of reality.

16:46.588 --> 16:52.052
We can have many instances of that reality
running on different computers.

16:53.178 --> 16:56.974
It samples thousands of actions
in simulation.

16:58.892 --> 17:02.229
The ground that they're encountering
has different slipperiness.

17:02.312 --> 17:03.856
It has different softness.

17:04.898 --> 17:08.318
We take all the experience
of these thousands of robots

17:08.402 --> 17:13.282
from simulation and download this
into a real robotic system.

17:15.492 --> 17:20.039
The test we're going to do today
is to see if it can adapt to new terrains.

17:21.206 --> 17:23.208
[tense music plays]

17:38.015 --> 17:40.017
[tense music continues]

17:53.322 --> 17:55.491
When the robot was going over foam,

17:55.574 --> 17:58.577
the feet movements
were stomping on the ground.

17:59.369 --> 18:02.206
Versus when it came on this poly surface,

18:03.248 --> 18:06.460
it was trying to adjust the motion,
so it doesn't slip.

18:08.670 --> 18:10.672
Then that is when it strikes you,

18:10.756 --> 18:14.051
"This is what machine learning
is bringing to the table."

18:22.476 --> 18:24.478
[cryptic music plays]

18:34.488 --> 18:35.864
[whimpering]

18:41.161 --> 18:44.123
We think the Robot Dog
could be really helpful

18:44.206 --> 18:46.166
in disaster response scenarios

18:46.250 --> 18:49.670
where you need to navigate
many different kinds of terrain.

18:52.631 --> 18:57.427
Or putting these dogs to do surveillance
in harsh environments.

18:57.970 --> 19:00.264
[cryptic music continues]

19:12.317 --> 19:13.819
[music crescendos]

19:15.696 --> 19:19.575
But most technology
runs into the challenge

19:19.658 --> 19:22.369
that there is some good they can do,
and there's some bad.

19:22.452 --> 19:23.996
[grim music plays]

19:24.079 --> 19:27.875
For example,
we can use nuclear technology for energy…

19:30.419 --> 19:33.797
but we also could develop atom bombs
which are really bad.

19:35.090 --> 19:38.468
This is what is known
as the dual-use problem.

19:39.052 --> 19:40.929
Fire is dual-use.

19:41.722 --> 19:44.308
Human intelligence is dual-use.

19:44.391 --> 19:48.645
So, needless to say,
artificial intelligence is also dual-use.

19:49.354 --> 19:53.984
It's really important
to think about AI used in context

19:54.693 --> 19:59.114
because, yes, it's terrific
to have a search-and-rescue robot

19:59.198 --> 20:02.284
that can help locate somebody
after an avalanche,

20:02.868 --> 20:05.871
but that same robot can be weaponized.

20:05.954 --> 20:07.080
[music builds]

20:08.457 --> 20:09.291
[gunshots]

20:15.088 --> 20:18.675
[Pulkit] When you see companies
using robotics

20:18.759 --> 20:21.094
for putting armed weapons on them,

20:21.178 --> 20:22.930
a part of you becomes mad.

20:23.931 --> 20:28.435
And a part of it is the realization
that when we put our technology,

20:28.518 --> 20:30.103
this is what's going to happen.

20:31.021 --> 20:34.441
[woman 4] This is a real
transformative technology.

20:34.524 --> 20:36.151
[grim music continues]

20:36.235 --> 20:38.028
These are weapon systems

20:38.111 --> 20:43.617
that could actually change
our safety and security in a dramatic way.

20:43.700 --> 20:45.035
[music crescendos]

20:46.161 --> 20:51.500
As of now, we are not sure
that machines can actually make

20:51.583 --> 20:54.962
the distinction
between civilians and combatants.

20:55.045 --> 20:57.047
[somber music plays]

20:57.130 --> 20:59.591
[indistinct voices]

21:01.802 --> 21:05.597
[Paul] Early in the war in Afghanistan,
I was part of an Army Ranger sniper team

21:05.681 --> 21:08.016
looking for enemy fighters
coming across the border.

21:09.685 --> 21:12.521
And they sent a little girl
to scout out our position.

21:13.939 --> 21:17.067
One thing that never came up
was the idea of shooting this girl.

21:18.193 --> 21:19.611
[children squealing]

21:19.695 --> 21:22.864
Under the laws of war,
that would have been legal.

21:22.948 --> 21:24.866
[indistinct chatter]

21:24.950 --> 21:27.369
They don't set an age
for enemy combatants.

21:29.079 --> 21:33.417
If you built a robot
to comply perfectly with the law of war,

21:33.500 --> 21:35.335
it would have shot this little girl.

21:36.420 --> 21:41.091
How would a robot know the difference
between what's legal and what is right?

21:41.174 --> 21:42.342
[indistinct chatter]

21:42.426 --> 21:43.302
[beeping]

21:43.385 --> 21:46.054
[man 12] When it comes to
autonomous drone warfare,

21:46.138 --> 21:49.933
they wanna take away the harm
that it places on American soldiers

21:50.017 --> 21:51.935
and the American psyche,

21:52.019 --> 21:57.149
uh, but the increase on civilian harm
ends up with Afghans,

21:57.232 --> 21:58.775
and Iraqis, and Somalians.

21:58.859 --> 22:00.944
[somber music plays]

22:01.445 --> 22:03.196
[indistinct chatter]

22:09.619 --> 22:14.416
I would really ask those who support
trusting AI to be used in drones,

22:15.375 --> 22:18.211
"What if your village was
on the receiving end of that?"

22:19.338 --> 22:20.297
[beeping]

22:23.550 --> 22:25.635
[man 13] AI is a dual-edged sword.

22:26.595 --> 22:30.724
It can be used for good,
which is what we'd use it for ordinarily,

22:31.558 --> 22:33.477
and at the flip of a switch,

22:34.561 --> 22:38.023
the technology becomes potentially
something that could be lethal.

22:38.106 --> 22:40.108
[thunder rumbles]

22:41.943 --> 22:43.945
[cryptic music plays]

22:47.032 --> 22:48.533
I'm a clinical pharmacologist.

22:49.618 --> 22:50.994
I have a team of people

22:51.078 --> 22:54.247
that are using artificial intelligence
to figure out drugs

22:54.331 --> 22:57.751
that will cure diseases
that are not getting any attention.

22:59.711 --> 23:04.132
It used to be with drug discoveries,
you would take a molecule that existed,

23:04.216 --> 23:06.885
and do a tweak to that
to get to a new drug.

23:08.261 --> 23:13.350
And now we've developed AI
that can feed us with millions of ideas,

23:13.892 --> 23:15.227
millions of molecules,

23:16.186 --> 23:19.231
and that opens up so many possibilities

23:19.314 --> 23:23.151
for treating diseases
we've never been able to treat previously.

23:25.153 --> 23:28.448
But there's definitely a dark side
that I never have thought

23:28.532 --> 23:29.741
that I would go to.

23:30.742 --> 23:33.078
[tense music plays]

23:33.161 --> 23:35.872
This whole thing started
when I was invited

23:35.956 --> 23:40.043
by an organization out of Switzerland
called the Spiez Laboratory

23:40.544 --> 23:44.423
to give a presentation
on the potential misuse of AI.

23:45.507 --> 23:47.509
[music intensifies]

23:48.343 --> 23:51.221
[man 14] Sean just sent me an email
with a few ideas

23:51.304 --> 23:55.308
of some ways we could misuse
our own artificial intelligence.

23:56.059 --> 24:00.355
And instead of asking our model
to create drug-like molecules,

24:00.439 --> 24:02.274
that could be used to treat diseases,

24:02.774 --> 24:06.403
let's see if we can generate
the most toxic molecules possible.

24:06.486 --> 24:08.447
[grim music plays]

24:10.198 --> 24:13.243
[Sean] I wanted to make the point,
could we use AI technology

24:13.326 --> 24:15.203
to design molecules that were deadly?

24:17.414 --> 24:20.083
[Fabio] And to be honest,
we thought it was going to fail

24:20.167 --> 24:24.504
because all we really did
was flip this zero to a one.

24:26.715 --> 24:30.385
And by inverting it,
instead of driving away from toxicity,

24:30.469 --> 24:32.220
now we're driving towards toxicity.

24:32.721 --> 24:33.555
And that's it.

24:33.638 --> 24:35.390
[music intensifies]

24:37.517 --> 24:40.729
While I was home,
the computer was doing the work.

24:41.521 --> 24:44.816
I mean, it was cranking through,
generating thousands of molecules,

24:45.650 --> 24:49.529
and we didn't have to do anything
other than just push "go."

24:50.071 --> 24:51.406
[music crescendos]

24:52.532 --> 24:53.992
[birds chirping]

24:54.493 --> 24:58.330
[Fabio] The next morning,
there was this file on my computer,

24:59.080 --> 25:03.376
and within it
were roughly 40,000 molecules

25:03.460 --> 25:05.253
that were potentially

25:05.337 --> 25:08.882
some of the most toxic molecules
known to humankind.

25:08.965 --> 25:10.133
[grim music plays]

25:10.217 --> 25:12.761
[Sean] The hairs on the back of my neck
stood up on end.

25:13.386 --> 25:14.554
I was blown away.

25:15.388 --> 25:19.017
The computer made
tens of thousands of ideas

25:19.100 --> 25:20.685
for new chemical weapons.

25:21.645 --> 25:26.274
Obviously, we have molecules
that look like and are VX analogs and VX

25:26.775 --> 25:27.609
in the data set.

25:28.360 --> 25:31.363
VX is one of the most potent
chemical weapons in the world.

25:31.863 --> 25:33.573
[reporter 3] New claims from police

25:33.657 --> 25:37.786
that the women seen attacking Kim Jong-nam
in this airport assassination

25:37.869 --> 25:41.248
were using a deadly nerve agent called VX.

25:41.748 --> 25:44.417
[Sean] It can cause death
through asphyxiation.

25:45.043 --> 25:47.629
This is a very potent molecule,

25:47.712 --> 25:52.092
and most of these molecules were predicted
to be even more deadly than VX.

25:53.301 --> 25:56.972
[Fabio] Many of them had never,
as far as we know, been seen before.

25:57.472 --> 26:00.767
And so, when Sean and I realized this,
we're like,

26:00.850 --> 26:02.727
"Oh, what have we done?" [chuckles]

26:02.811 --> 26:04.688
[grim music continues]

26:04.771 --> 26:09.192
[Sean] I quickly realized
that we had opened Pandora's box,

26:09.901 --> 26:12.696
and I said, "Stop.
Don't do anything else. We're done."

26:13.905 --> 26:17.158
"Just make me the slides
that I need for the presentation."

26:19.202 --> 26:20.704
When we did this experiment,

26:20.787 --> 26:23.873
I was thinking, "What's the worst thing
that could possibly happen?"

26:26.251 --> 26:30.255
But now I'm like, "We were naive.
We were totally naive in doing it."

26:31.339 --> 26:33.383
[music intensifies]

26:33.466 --> 26:36.928
The thing that terrifies me the most
is that anyone could do what we did.

26:38.930 --> 26:40.765
All it takes is the flip of a switch.

26:40.849 --> 26:42.851
[somber music plays]

26:42.934 --> 26:46.187
How do we control
this technology before it's used

26:46.271 --> 26:50.942
potentially to do something
that's utterly destructive?

26:55.780 --> 27:00.285
[woman 1] At the heart of the conversation
around artificial intelligence

27:00.368 --> 27:03.538
and how do we choose to use it in society

27:04.289 --> 27:08.835
is a race between the power,
with which we develop technologies,

27:08.918 --> 27:11.379
and the wisdom that we have to govern it.

27:11.463 --> 27:13.256
[somber music continues]

27:13.340 --> 27:16.926
There are the obvious
moral and ethical implications

27:17.010 --> 27:20.138
of the same thing
that powers our smartphones

27:20.221 --> 27:23.433
being entrusted
with the moral decision to take a life.

27:25.727 --> 27:31.191
I work with the Future Of Life Institute,
a community of scientist activists.

27:31.733 --> 27:33.443
We're overall trying to show

27:33.526 --> 27:38.698
that there is this other side
to speeding up and escalating automation.

27:38.782 --> 27:42.619
[Emilia] But we're trying to make sure
that technologies we create

27:42.702 --> 27:45.038
are used in a way
that is safe and ethical.

27:46.247 --> 27:49.959
Let's have conversations
about rules of engagement,

27:50.043 --> 27:54.005
and codes of conduct in using AI
throughout our weapons systems.

27:54.798 --> 27:59.135
Because we are now seeing
"enter the battlefield" technologies

27:59.219 --> 28:01.680
that can be used to kill autonomously.

28:02.263 --> 28:03.431
[beeping]

28:04.516 --> 28:05.684
[rocket whistles]

28:05.767 --> 28:07.268
[explosion rumbles]

28:10.230 --> 28:15.110
In 2021, the UN released
a report on the potential use

28:15.193 --> 28:19.364
of a lethal autonomous weapon
on the battlefield in Libya.

28:20.073 --> 28:23.910
[reporter 4] A UN panel said that a drone
flying in the Libyan civil war last year

28:23.993 --> 28:27.288
had been programmed
to attack targets autonomously.

28:28.289 --> 28:31.209
[Emilia] If the UN reporting is accurate,

28:31.292 --> 28:34.963
this would be
a watershed moment for humanity.

28:35.046 --> 28:37.090
Because it marks a use case

28:37.173 --> 28:42.137
where an AI made the decision
to take a life, and not a human being.

28:42.220 --> 28:44.180
[dramatic music plays]

28:47.517 --> 28:48.351
[beeping]

28:49.686 --> 28:51.688
[Stacie] You're seeing advanced
autonomous weapons

28:51.771 --> 28:55.150
beginning to be used
in different places around the globe.

28:56.276 --> 28:58.278
There were reports out of Israel.

28:58.361 --> 29:00.196
[dramatic music continues]

29:00.280 --> 29:05.702
Azerbaijan used autonomous systems
to target Armenian air defenses.

29:07.370 --> 29:09.998
[Sean] It can fly around
the battlefield for hours,

29:10.081 --> 29:12.500
looking for things to hit on its own,

29:12.584 --> 29:16.087
and then plow into them
without any kind of human intervention.

29:16.755 --> 29:18.298
[Stacie] And we've seen recently

29:18.381 --> 29:21.760
these different videos
that are posted in Ukraine.

29:23.094 --> 29:26.890
[Paul] It's unclear what mode they might
have been in when they were operating.

29:26.973 --> 29:30.393
Was a human in the loop,
choosing what targets to attack,

29:30.477 --> 29:32.729
or was the machine doing that on its own?

29:32.812 --> 29:36.524
But there will certainly
come a point in time,

29:36.608 --> 29:40.195
whether it's already happened in Libya,
Ukraine or elsewhere,

29:40.278 --> 29:44.449
where a machine makes its own decision
about whom to kill on the battlefield.

29:44.532 --> 29:46.534
[music crescendos]

29:47.035 --> 29:50.997
[Izumi] Machines exercising
lethal power against humans

29:51.080 --> 29:53.374
without human intervention

29:53.458 --> 29:57.337
is politically unacceptable,
morally repugnant.

29:59.130 --> 30:01.299
Whether the international community

30:01.382 --> 30:05.011
will be sufficient
to govern those challenges

30:05.094 --> 30:06.888
is a big question mark.

30:06.971 --> 30:08.848
[somber music plays]

30:08.932 --> 30:12.685
[Emilia] If we look towards the future,
even just a few years from now,

30:12.769 --> 30:15.730
what the landscape looks like
is very scary,

30:16.564 --> 30:20.485
given that the amount
of capital and human resource

30:20.568 --> 30:23.404
going into making AI more powerful

30:23.488 --> 30:26.032
and using it
for all of these different applications,

30:26.115 --> 30:26.950
is immense.

30:27.033 --> 30:29.327
[tense music plays]

30:33.373 --> 30:34.958
[indistinct chatter]

30:39.254 --> 30:41.214
Oh my God, this guy.

30:41.756 --> 30:43.424
[Brandon] He knows he can't win.

30:44.259 --> 30:46.678
Oh… [muttering]

30:46.761 --> 30:51.099
When I see AI win at different problems,
I find it inspirational.

30:51.683 --> 30:53.977
Going for a little Hail Mary action.

30:54.477 --> 30:59.524
And you can apply those same tactics,
techniques, procedures to real aircraft.

31:01.401 --> 31:04.404
-[friend] Good game.
-[Brandon] All right, good game. [laughs]

31:06.948 --> 31:08.157
[sighs]

31:08.658 --> 31:09.909
It's surprising to me

31:09.993 --> 31:14.122
that people continue to make statements
about what AI can't do. Right?

31:14.205 --> 31:17.166
"Oh, it'll never be able
to beat a world champion in chess."

31:17.250 --> 31:19.294
[tense classical music plays]

31:20.211 --> 31:22.672
[reporter 5] An IBM computer
has made a comeback

31:22.755 --> 31:25.925
in Game 2 of its match
with world chess champion, Garry Kasparov.

31:27.093 --> 31:30.889
[commentator] Whoa! Kasparov has resigned!

31:31.598 --> 31:34.642
[Kasporov] When I see something
that is well beyond my understanding,

31:34.726 --> 31:38.062
I'm scared. And that was something
well beyond my understanding.

31:39.355 --> 31:41.107
[Brandon] And then people would say,

31:41.190 --> 31:44.402
"It'll never be able to beat
a world champion in the game of Go."

31:44.485 --> 31:50.700
[Go champion] I believe human intuition
is still too advanced for A.I.

31:50.783 --> 31:52.827
to have caught up.

31:53.411 --> 31:55.204
[tense music continues]

31:55.288 --> 31:58.416
[man 15] Go is one of the most
complicated games anyone can learn

31:58.499 --> 32:02.211
because the number of moves on the board,
when you do the math,

32:02.295 --> 32:05.256
equal more atoms
than there are in the entire universe.

32:06.799 --> 32:08.968
There was a team at Google
called DeepMind,

32:09.052 --> 32:11.471
and they created a program called AlphaGo

32:11.554 --> 32:14.265
to be able to beat
the world's best players.

32:14.349 --> 32:16.476
[officiator] Wow.

32:16.559 --> 32:18.394
Congratulations to…

32:18.478 --> 32:19.437
-AlphaGo
-AlphaGo.

32:19.520 --> 32:22.774
A computer program
has just beaten a 9 dan professional.

32:25.610 --> 32:31.532
[Brandon] Then DeepMind chose StarCraft
as kind of their next AI challenge.

32:33.743 --> 32:38.081
StarCraft is perhaps the most popular
real-time strategy game of all time.

32:40.333 --> 32:44.712
AlphaStar became famous
when it started defeating world champions.

32:45.338 --> 32:48.800
[host 1] AlphaStar
absolutely smashing Immortal Arc.

32:48.883 --> 32:49.717
[host 2] Know what?

32:49.801 --> 32:52.553
This is not gonna be a fight
that the pros can win.

32:53.680 --> 32:54.806
It's kind of ridiculous.

32:54.889 --> 32:57.558
[tense classical music continues]

32:57.642 --> 33:00.895
[Brandon] Professional gamers say,
"I would never try that tactic."

33:00.979 --> 33:04.816
"I would never try that strategy.
That's something that's not human."

33:07.151 --> 33:10.655
And that was perhaps,
you know, the "a-ha" moment for me.

33:10.738 --> 33:12.657
[music crescendos]

33:13.574 --> 33:16.661
I came to realize the time is now.

33:17.412 --> 33:21.082
There's an important technology
and an opportunity to make a difference.

33:21.165 --> 33:23.167
[somber music plays]

33:24.502 --> 33:29.382
I only knew the problems that I had faced
as a SEAL in close-quarters combat,

33:30.383 --> 33:34.470
but one of my good friends,
who was an F-18 pilot, told me,

33:34.554 --> 33:37.724
"We have the same problem
in the fighter jet community."

33:37.807 --> 33:39.434
"They are jamming communications."

33:39.517 --> 33:42.562
"There are proliferated
surface-to-air missile sites

33:42.645 --> 33:44.439
that make it too dangerous to operate."

33:47.483 --> 33:50.987
Imagine if we had a fighter jet
that was commanded by an AI.

33:51.070 --> 33:52.739
[host 3] Welcome
to the AlphaDogfights.

33:52.822 --> 33:56.159
We're a couple of minutes away
from this first semifinal.

33:56.242 --> 33:59.871
[Brandon] DARPA, the Defense
Advanced Research Projects Agency,

33:59.954 --> 34:03.624
had seen AlphaGo and AlphaStar,

34:04.292 --> 34:08.171
and so this idea of the AlphaDogfight
competition came to life.

34:09.005 --> 34:11.466
[host 4] It's what you wanna see
your fighter pilots do.

34:11.549 --> 34:13.634
[host 3] This looks like
human dogfighting.

34:13.718 --> 34:15.511
[tense music plays]

34:15.595 --> 34:19.057
[Brandon] Dogfighting is
fighter-on-fighter aircraft going at it.

34:19.849 --> 34:22.852
You can think about it
as a boxing match in the sky.

34:23.853 --> 34:26.314
Maybe people have seen the movie Top Gun.

34:26.397 --> 34:30.068
-[character] Can we outrun these guys?
-[Maverick] Not their missiles and guns.

34:30.151 --> 34:31.277
[character] It's a dogfight.

34:35.531 --> 34:39.410
[Brandon] Learning to master dogfighting
can take eight to ten years.

34:42.288 --> 34:46.209
It's an extremely complex challenge
to build AI around.

34:47.043 --> 34:49.045
[dramatic music plays]

34:49.128 --> 34:51.130
[keyboard tapping]

34:54.092 --> 34:58.679
The prior approaches to autonomy
and dogfighting tended to be brittle.

34:59.222 --> 35:03.017
[man 16] We figured machine learning was
probably the way to solve this problem.

35:04.477 --> 35:08.189
At first, the AI knew nothing
about the world in which it was dropped.

35:08.272 --> 35:11.025
It didn't know it was flying
or what dogfighting was.

35:11.109 --> 35:12.735
It didn't know what an F-16 is.

35:13.236 --> 35:15.988
All it knew
was the available actions it could take,

35:16.072 --> 35:18.407
and it would start
to randomly explore those actions.

35:19.325 --> 35:23.204
[colleague] The blue plane's been training
for only a small amount of time.

35:23.287 --> 35:25.832
You can see it wobbling back and forth,

35:25.915 --> 35:30.545
uh, flying very erratically,
generally away from its adversary.

35:31.587 --> 35:34.257
As the fight progresses,
we can see blue is starting

35:34.340 --> 35:36.134
to establish here its game plan.

35:36.759 --> 35:38.636
It's more in a position to shoot.

35:39.178 --> 35:41.305
Once in a while,
the learning algorithm said,

35:41.389 --> 35:43.891
"Here's a cookie.
Keep doing more of that."

35:45.143 --> 35:49.147
We can take advantage of computer power
and train the agents many times

35:49.230 --> 35:50.064
in parallel.

35:51.357 --> 35:52.775
It's like a basketball team.

35:53.276 --> 35:55.778
Instead of playing the same team
over and over again,

35:55.862 --> 35:59.198
you're traveling the world
playing 512 different teams,

35:59.699 --> 36:00.950
all at the same time.

36:01.492 --> 36:03.452
You can get very good, very fast.

36:04.162 --> 36:07.456
We were able to run that simulation 24/7

36:07.540 --> 36:11.919
and get something like 30 years
of pilot training time in, in 10 months.

36:12.003 --> 36:12.837
[music builds]

36:12.920 --> 36:15.673
We went from barely able
to control the aircraft

36:15.756 --> 36:17.717
to being a stone-cold assassin.

36:19.010 --> 36:23.514
Under training, we were competing only
against other artificial intelligence.

36:24.473 --> 36:28.561
But competing against humans directly
was kind of the ultimate target.

36:34.192 --> 36:35.610
My name is Mike Benitez,

36:36.110 --> 36:38.362
I'm a Lieutenant Colonel
in the U.S. Air Force.

36:39.155 --> 36:41.157
Been on active duty about 25 years.

36:42.825 --> 36:44.869
I've got 250 combat missions

36:45.578 --> 36:47.538
and I'm a weapons school graduate,

36:48.039 --> 36:49.832
which is Air Force version of Top Gun.

36:52.627 --> 36:55.171
I've never actually flown against AI.

36:55.254 --> 36:58.549
So I'm pretty excited
to see how well I can do.

36:59.634 --> 37:03.054
[commander] We got now a 6,000 feet
offensive set up nose-to-nose.

37:04.388 --> 37:05.223
Fight's on.

37:05.306 --> 37:06.724
[tense music plays]

37:06.807 --> 37:08.309
[air rushing]

37:09.852 --> 37:10.978
[machine gun fire]

37:13.314 --> 37:14.148
He's gone now.

37:14.732 --> 37:16.651
Yeah, that's actually really interesting.

37:16.734 --> 37:18.778
[muttering indistinctly]

37:19.278 --> 37:20.696
[machine gun fire]

37:20.780 --> 37:23.658
Dead. Got him. Flawless victory.

37:23.741 --> 37:25.409
[chuckling]

37:25.910 --> 37:27.453
All right, round two.

37:27.536 --> 37:30.039
[tense music continues]

37:31.290 --> 37:33.209
[machine gun fire]

37:35.461 --> 37:40.466
What the artificial intelligence is doing
is maneuvering with such precision,

37:40.967 --> 37:43.219
uh, that I just can't keep up with it.

37:43.302 --> 37:44.679
[air rushing]

37:44.762 --> 37:46.013
[machine gun fire]

37:46.847 --> 37:48.391
[air rushing]

37:48.474 --> 37:49.725
Right into the merge.

37:50.309 --> 37:51.894
Oh, now you're gone.

37:51.978 --> 37:53.062
[machine gun fire]

37:53.145 --> 37:53.980
Got him!

37:54.063 --> 37:55.022
Still got me.

37:55.523 --> 37:56.857
[laughing]

37:58.567 --> 38:00.069
[Brett] AI is never scared.

38:00.736 --> 38:03.781
There's a human emotional element
in the cockpit an AI won't have.

38:03.864 --> 38:04.907
[music rises]

38:04.991 --> 38:08.077
One of the more interesting strategies
our AI developed,

38:08.160 --> 38:10.121
was what we call the face shot.

38:10.621 --> 38:14.000
Usually a human wants to shoot from behind

38:14.083 --> 38:16.377
because it's hard for them
to shake you loose.

38:17.044 --> 38:20.381
They don't try face shots
because you're playing a game of chicken.

38:20.464 --> 38:21.340
[beeping]

38:21.424 --> 38:25.511
When we come head-on,
3,000 feet away to 500 feet away

38:25.594 --> 38:27.096
can happen in a blink of an eye.

38:27.596 --> 38:31.183
You run a high risk of colliding,
so humans don't try it.

38:31.267 --> 38:32.393
[high-pitched tone]

38:32.893 --> 38:35.938
The AI, unless it's told to fear death,
will not fear death.

38:36.022 --> 38:37.023
[machine gun fire]

38:37.106 --> 38:40.693
[Mike] All good. Feels like
I'm fighting against a human, uh,

38:40.776 --> 38:44.113
a human that has a reckless abandonment
for safety. [chuckles]

38:45.489 --> 38:47.325
He's not gonna survive this last one.

38:48.284 --> 38:49.869
[air rushing]

38:50.369 --> 38:52.038
[tense music continues]

38:54.790 --> 38:56.292
[wind whistling]

38:57.168 --> 38:58.461
He doesn't have enough time.

39:00.629 --> 39:01.464
Ah!

39:01.964 --> 39:02.965
[Brett] Good night.

39:03.049 --> 39:04.008
[beeping]

39:04.091 --> 39:04.925
[Mike] I'm dead.

39:16.812 --> 39:17.980
It's humbling to know

39:18.064 --> 39:20.983
that I might not even be
the best thing for this mission,

39:21.484 --> 39:24.320
and that thing could be something
that replaces me one day.

39:25.696 --> 39:26.989
[colleague] Same 6 CAV.

39:27.615 --> 39:28.866
One thousand offset.

39:29.367 --> 39:32.078
[Brandon] With this AI pilot
commanding fighter aircraft,

39:32.828 --> 39:34.830
the winning is relentless, it's dominant.

39:34.914 --> 39:37.249
It's not just winning by a wide range.

39:37.333 --> 39:41.545
It's, "Okay, how can we get that
onto our aircraft?" It's that powerful.

39:41.629 --> 39:43.589
[melodic music plays]

39:43.672 --> 39:47.802
[Nathan] It's realistic to expect
that AI will be piloting an F-16,

39:47.885 --> 39:49.970
and it will not be that far out.

39:51.305 --> 39:56.769
[Brandon] If you're going up against
an AI pilot that has a 99.99999% win rate,

39:56.852 --> 39:58.062
you don't stand a chance.

39:58.145 --> 39:59.522
[tense music plays]

39:59.605 --> 40:02.733
When I think about
one AI pilot being unbeatable,

40:02.817 --> 40:06.779
I think about what a team of 50, or 100,

40:07.279 --> 40:12.535
or 1,000 AI pilots
can continue to, uh, achieve.

40:13.702 --> 40:17.415
Swarming is a team
of highly intelligent aircraft

40:17.498 --> 40:18.791
that work with each other.

40:19.291 --> 40:23.462
They're sharing information about
what to do, how to solve a problem.

40:23.546 --> 40:24.588
[beeping]

40:25.172 --> 40:30.469
Swarming will be a game-changing
and transformational capability

40:30.553 --> 40:32.638
to our military and our allies.

40:33.139 --> 40:35.433
[crickets chirping]

40:35.516 --> 40:37.852
[dramatic music plays]

40:44.316 --> 40:45.818
[music intensifies]

41:04.920 --> 41:07.256
[muffled radio music]

41:12.553 --> 41:14.346
[tense music plays]

41:19.643 --> 41:21.061
[wind whistling]

41:21.145 --> 41:22.062
[buzzing]

41:25.608 --> 41:27.318
[truck accelerating]

41:27.401 --> 41:28.486
[music builds]

41:42.750 --> 41:47.379
[controller] Target has been acquired,
and the drones are tracking him.

41:56.722 --> 41:58.057
[music crescendos]

42:01.936 --> 42:03.604
[controller] Here comes the land.

42:07.566 --> 42:10.402
[man 17] Primary goal
of the swarming research we're working on

42:11.153 --> 42:13.697
is to deploy a large number of drones

42:13.781 --> 42:17.910
over an area that is hard to get to
or dangerous to get to.

42:17.993 --> 42:19.995
[cryptic music plays]

42:20.079 --> 42:21.622
[buzzing]

42:21.705 --> 42:26.085
The Army Research Lab has been supporting
this particular research project.

42:26.919 --> 42:28.963
If you want to know what's in a location,

42:29.046 --> 42:32.883
but it's hard to get to that area,
or it's a very large area,

42:33.676 --> 42:35.886
then deploying a swarm
is a very natural way

42:35.970 --> 42:38.389
to extend the reach of individuals

42:38.472 --> 42:41.934
and collect information
that is critical to the mission.

42:42.935 --> 42:44.770
[music intensifies]

42:46.689 --> 42:48.983
So, right now in our swarm deployment,

42:49.066 --> 42:53.988
we essentially give a single command
to go track the target of interest.

42:54.488 --> 42:57.283
Then the drones go
and do all of that on their own.

42:59.493 --> 43:04.081
Artificial intelligence allows
the robots to move collectively as a swarm

43:04.164 --> 43:05.708
in a decentralized manner.

43:06.792 --> 43:08.877
[melodic music plays]

43:10.671 --> 43:12.506
In the swarms in nature that we see,

43:13.299 --> 43:18.178
there's no boss,
no main animal telling them what to do.

43:20.556 --> 43:25.019
The behavior is emerging
out of each individual animal

43:25.102 --> 43:27.104
following a few simple rules.

43:27.688 --> 43:32.443
And out of that grows this emergent
collective behavior that you see.

43:32.526 --> 43:33.861
[buzzing]

43:33.944 --> 43:37.031
What's awe-inspiring
about swarms in nature

43:37.114 --> 43:39.992
is the graceful ability
in which they move.

43:40.576 --> 43:44.288
It's as if they were built
to be a part of this group.

43:46.790 --> 43:51.128
Ideally, what we'd love to see
with our drone swarm is,

43:51.211 --> 43:53.172
much like in the swarm in nature,

43:53.672 --> 43:56.717
decisions being made
by the group collectively.

43:56.800 --> 43:59.428
[melodic music continues]

43:59.928 --> 44:02.765
The other piece of inspiration for us

44:02.848 --> 44:06.268
comes in the form
of reliability and resiliency.

44:07.311 --> 44:09.188
That swarm will not go down

44:09.271 --> 44:13.567
if one individual animal
doesn't do what it's supposed to do.

44:13.651 --> 44:15.110
[buzzing]

44:15.194 --> 44:18.697
Even if one of the agents falls out,
or fails,

44:18.781 --> 44:20.866
or isn't able to complete the task,

44:21.909 --> 44:23.369
the swarm will continue.

44:25.204 --> 44:27.873
And ultimately,
that's what we'd like to have.

44:29.333 --> 44:33.879
We have this need in combat scenarios
for identifying enemy aircraft,

44:33.962 --> 44:37.841
and it used to be we required
one person controlling one robot.

44:38.592 --> 44:40.552
As autonomy increases,

44:40.636 --> 44:43.555
I hope we will get to see
a large number of robots

44:43.639 --> 44:46.558
being controlled
by a very small number of people.

44:47.851 --> 44:50.854
I see no reason why we couldn't achieve
a thousand eventually

44:51.355 --> 44:54.942
because each agent
will be able to act of its own accord,

44:55.025 --> 44:56.443
and the sky's the limit.

44:57.027 --> 44:59.071
We can scale our learning…

44:59.154 --> 45:03.325
[Justin B.] We've been working on swarming
in simulation for quite some time,

45:03.409 --> 45:06.829
and it is time to bring
that to real-world aircraft.

45:07.454 --> 45:12.042
We expect to be doing
three robots at once over the network,

45:12.126 --> 45:15.129
and then starting
to add more and more capabilities.

45:15.879 --> 45:18.549
We want to be able
to test that on smaller systems,

45:18.632 --> 45:22.261
but take those same concepts
and apply them to larger systems,

45:22.344 --> 45:23.679
like a fighter jet.

45:24.513 --> 45:26.014
[Brandon] We talk a lot about,

45:26.098 --> 45:31.937
how do you give a platoon
the combat power of a battalion?

45:32.020 --> 45:33.939
[dramatic music plays]

45:34.982 --> 45:39.528
Or a battalion
the combat power of a brigade?

45:39.611 --> 45:41.488
You can do that with swarming.

45:42.614 --> 45:45.200
And when you can unlock
that power of swarming,

45:45.284 --> 45:48.078
you have just created
a new strategic deterrence

45:48.162 --> 45:49.455
to military aggression.

45:49.538 --> 45:52.249
[dramatic music continues]

45:52.332 --> 45:57.004
[Bob] I think the most exciting thing
is the number of young men and women

45:57.087 --> 46:00.299
who we will save
if we really do this right.

46:01.091 --> 46:03.594
And we trade machines

46:04.553 --> 46:05.846
rather than human lives.

46:06.638 --> 46:10.893
Some argue that autonomous weapons
will make warfare more precise

46:10.976 --> 46:12.311
and more humane,

46:12.853 --> 46:15.397
but it's actually difficult to predict

46:15.481 --> 46:19.443
exactly how autonomous weapons
might change warfare ahead of time.

46:21.320 --> 46:23.238
It's like the invention
of the Gatling gun.

46:23.322 --> 46:24.990
[grim music plays]

46:25.073 --> 46:26.700
Richard Gatling was an inventor,

46:27.201 --> 46:30.954
and he saw soldiers coming back,
wounded in the Civil War,

46:32.289 --> 46:35.292
and wanted to find ways
to make warfare more humane.

46:36.293 --> 46:39.797
To reduce the number of soldiers
that were killed in war

46:40.422 --> 46:42.633
by reducing the number
of soldiers in the battle.

46:42.716 --> 46:44.009
[music builds]

46:44.092 --> 46:48.388
And so he invented the Gatling gun,
an automated gun turned by a crank

46:48.472 --> 46:50.516
that could automate the process of firing.

46:53.268 --> 46:57.981
It increased effectively by a hundredfold
the firepower that soldiers could deliver.

46:58.065 --> 47:00.734
[grim music continues]

47:01.235 --> 47:05.239
Oftentimes, efforts to make warfare
more precise and humane…

47:05.322 --> 47:06.448
[tense music plays]

47:06.532 --> 47:07.991
…can have the opposite effect.

47:10.160 --> 47:13.455
[Arash] Think about the effect
of one errant drone strike

47:13.539 --> 47:14.540
in a rural area

47:14.623 --> 47:17.209
that drives the local populace
against the United States,

47:17.292 --> 47:20.712
against the local government.
You know, supposedly the good guys.

47:20.796 --> 47:22.506
[tense music continues]

47:22.589 --> 47:25.008
Now magnify that by 1,000.

47:26.718 --> 47:28.720
[Emilia] The creation of a weapon system

47:28.804 --> 47:34.560
that is cheap, scalable,
and doesn't require human operators

47:34.643 --> 47:37.896
drastically changes
the actual barriers to conflict.

47:40.107 --> 47:44.486
It keeps me up at night to think
of a world where war is ubiquitous,

47:44.987 --> 47:48.657
and we no longer carry
the human and financial cost of war

47:48.740 --> 47:51.410
because we're just so far removed from…

47:52.369 --> 47:54.037
the lives that will be lost.

47:55.038 --> 47:57.541
[somber melodic music plays]

47:59.459 --> 48:01.420
[Sean] This whole thing is haunting me.

48:02.212 --> 48:05.924
I just needed an example
of artificial intelligence misuse.

48:06.800 --> 48:10.888
The unanticipated consequences
of doing that simple thought experiment

48:10.971 --> 48:12.848
have gone way too far.

48:17.352 --> 48:18.729
When I gave the presentation

48:18.812 --> 48:22.107
on the toxic molecules
created by AI technology,

48:22.608 --> 48:24.318
the audience's jaws dropped.

48:29.406 --> 48:33.660
[Fabio] The next decision was whether
we should publish this information.

48:34.912 --> 48:36.914
On one hand, you want to warn the world

48:36.997 --> 48:40.125
of these sorts of capabilities,
but on the other hand,

48:40.208 --> 48:44.087
you don't want to give somebody the idea
if they had never had it before.

48:46.381 --> 48:48.133
We decided it was worth publishing

48:48.216 --> 48:52.679
to maybe find some ways
to mitigate the misuse of this type of AI

48:52.763 --> 48:54.139
before it occurs.

48:54.222 --> 48:56.224
[grim music plays]

49:01.897 --> 49:04.775
The general public's reaction
was shocking.

49:04.858 --> 49:07.110
[tense music plays]

49:07.194 --> 49:10.656
We can see the metrics on the page,
how many people have accessed it.

49:10.739 --> 49:14.451
The kinds of articles we normally write,
we're lucky if we get--

49:14.534 --> 49:19.831
A few thousand people look at our article
over a period of a year or multiple years.

49:19.915 --> 49:22.084
It was 10,000 people
had read it within a week.

49:22.167 --> 49:25.337
Then it was 20,000,
then it was 30,000, then it was 40,000,

49:25.837 --> 49:28.715
and we were up to 10,000 people a day.

49:30.258 --> 49:33.512
[Sean] We've done The Economist,
the Financial Times.

49:35.639 --> 49:39.977
Radiolab, you know, they reached out.
Like, I've heard of Radiolab!

49:40.060 --> 49:41.311
[music crescendos]

49:41.937 --> 49:45.899
But then the reactions turned
into this thing that's out of control.

49:45.983 --> 49:48.235
[tense music continues]

49:49.778 --> 49:53.532
When we look at those tweets, it's like,
"Oh my God, could they do anything worse?"

49:54.324 --> 49:55.993
Why did they do this?

49:57.828 --> 49:59.329
[music crescendos]

50:01.164 --> 50:04.501
And then we got an invitation
I never would have anticipated.

50:04.584 --> 50:07.087
[dramatic music plays]

50:08.797 --> 50:12.926
There was a lot of discussion
inside the White House about the article,

50:13.010 --> 50:15.345
and they wanted to talk to us urgently.

50:18.849 --> 50:20.809
Obviously, it's an incredible honor

50:20.892 --> 50:23.020
to be able
to talk to people at this level.

50:23.603 --> 50:25.272
But then it hits you

50:25.355 --> 50:28.900
like, "Oh my goodness,
it's the White House. The boss."

50:29.693 --> 50:33.196
This involved putting together
data sets that were open source…

50:33.280 --> 50:37.701
And in about six hours, the model was able
to generate about over 40,000…

50:37.784 --> 50:41.038
[Sean] They asked questions
about how much computing power you needed,

50:41.872 --> 50:43.832
and we told them it was nothing special.

50:44.332 --> 50:48.211
Literally a standard run-of-the-mill,
six-year-old Mac.

50:49.546 --> 50:51.256
And that blew them away.

50:52.049 --> 50:54.468
[dramatic music continues]

50:54.968 --> 50:59.473
The folks that are in charge
of understanding chemical warfare agents

50:59.556 --> 51:04.019
and governmental agencies,
they had no idea of this potential.

51:04.102 --> 51:06.104
[music intensifies]

51:06.605 --> 51:09.816
We've got this cookbook
to make these chemical weapons,

51:10.650 --> 51:15.572
and in the hands of a bad actor
that has malicious intent

51:16.573 --> 51:18.992
it could be utterly horrifying.

51:19.534 --> 51:21.203
[grim music plays]

51:21.703 --> 51:23.205
People have to sit up and listen,

51:23.288 --> 51:26.458
and we have to take steps
to either regulate the technology

51:27.250 --> 51:30.670
or constrain it in a way
that it can't be misused.

51:31.880 --> 51:35.175
Because the potential for lethality…

51:36.176 --> 51:37.344
is terrifying.

51:40.680 --> 51:45.977
The question of the ethics of AI
is largely addressed by society,

51:46.561 --> 51:50.273
not by the engineers or technologists,
the mathematicians.

51:51.608 --> 51:52.442
[beeping]

51:52.526 --> 51:56.822
Every technology that we bring forth,
every novel innovation,

51:56.905 --> 52:00.617
ultimately falls under the purview
of how society believes we should use it.

52:00.700 --> 52:02.536
[somber music plays]

52:03.036 --> 52:06.498
[Bob] Right now,
the Department of Defense says,

52:06.581 --> 52:09.960
"The only thing that is saying
we are going to kill something

52:10.043 --> 52:11.920
on the battlefield is a human."

52:12.504 --> 52:14.548
A machine can do the killing,

52:15.674 --> 52:18.927
but only at the behest
of a human operator,

52:19.636 --> 52:21.429
and I don't see that ever changing.

52:21.513 --> 52:23.390
[somber music continues]

52:24.808 --> 52:28.103
[Arash] They assure us
that this type of technology will be safe.

52:29.729 --> 52:33.692
But the United States military just
doesn't have a trustworthy reputation

52:33.775 --> 52:35.485
with drone warfare.

52:36.820 --> 52:41.783
And so, when it comes
to trusting the U.S. military with AI,

52:41.867 --> 52:45.036
I would say, you know, the track record
kinda speaks for itself.

52:46.288 --> 52:50.125
[Paul] The U.S. Defense Department policy
on the use of autonomy in weapons

52:50.208 --> 52:52.919
does not ban any kind of weapon system.

52:53.003 --> 52:56.715
And even if militaries
might not want autonomous weapons,

52:56.798 --> 53:01.678
we could see militaries handing over
more decisions to machines

53:01.761 --> 53:03.680
just to keep pace with competitors.

53:04.764 --> 53:08.351
And that could drive militaries
to automate decisions

53:08.435 --> 53:09.978
that they may not want to.

53:12.022 --> 53:13.440
[Bob] Vladimir Putin said,

53:13.523 --> 53:16.693
"Whoever leads in AI
is going to rule the world."

53:17.736 --> 53:23.325
President Xi has made it clear that AI
is one of the number one technologies

53:23.408 --> 53:25.702
that China wants to dominate in.

53:26.786 --> 53:29.831
We're clearly
in a technological competition.

53:33.418 --> 53:35.670
[Brandon] You hear people talk
about guardrails,

53:36.463 --> 53:39.424
and I believe
that is what people should be doing.

53:40.467 --> 53:45.180
But there is a very real race
for AI superiority.

53:45.263 --> 53:46.264
[birds chirping]

53:47.265 --> 53:51.603
And our adversaries, whether it's China,
whether it's Russia, whether it's Iran,

53:52.187 --> 53:56.566
are not going to give two thoughts
to what our policy says around AI.

53:57.943 --> 54:00.320
[birds singing]

54:00.820 --> 54:04.324
You're seeing a lot more conversations
around AI policy,

54:06.117 --> 54:09.287
but I wish more leaders
would have the conversation

54:09.371 --> 54:11.706
saying, ''How quickly
can we build this thing?

54:12.707 --> 54:15.168
Let's resource the heck out of it
and build it."

54:15.919 --> 54:17.462
[dramatic music plays]

54:17.545 --> 54:18.838
[horns honking]

54:24.177 --> 54:26.388
[indistinct chatter]

54:26.888 --> 54:29.057
[inaudible conversation]

54:29.557 --> 54:31.017
[beeping]

54:33.478 --> 54:38.358
We are at the Association of the U.S.
Army's biggest trade show of the year.

54:39.609 --> 54:44.572
Basically, any vendor who is selling
a product or technology into a military

54:44.656 --> 54:46.616
will be exhibiting.

54:47.659 --> 54:50.537
[man 18] The Tyndall Air Force Base
has four of our robots

54:50.620 --> 54:53.748
that patrol their base
24 hours a day, 7 days a week.

54:55.750 --> 55:00.130
We can add everything from cameras
to sensors to whatever you need.

55:00.213 --> 55:05.135
Manipulator arms. Again, just to complete
the mission that the customer has in mind.

55:06.678 --> 55:08.638
[man 19] What if your enemy introduces AI?

55:09.431 --> 55:12.976
A fighting system that thinks
faster than you, responds faster,

55:13.059 --> 55:16.062
than what a human being can do?
We've got to be prepared.

55:17.605 --> 55:21.359
We train our systems
to collect intel on the enemy,

55:22.027 --> 55:26.531
managing enemy targets
with humans supervising the kill chain.

55:27.115 --> 55:28.491
[music crescendos]

55:33.204 --> 55:34.956
-[Brandon] Hi, General.
-How you doing?

55:35.040 --> 55:37.208
[Brandon] Good, sir. How are you? Um…

55:37.709 --> 55:40.962
I'll just say
no one is investing more in an AI pilot.

55:41.046 --> 55:42.630
Our AI pilot's called Hivemind,

55:43.298 --> 55:47.135
so we applied it to our quadcopter Nova.
It goes inside buildings,

55:47.218 --> 55:49.387
explores them
ahead of special operation forces

55:49.471 --> 55:50.805
and infantry forces.

55:50.889 --> 55:52.891
We're applying Hivemind to V-BAT,

55:52.974 --> 55:56.811
so I think about, you know,
putting up hundreds of those teams.

55:56.895 --> 55:58.646
Whether it's the Taiwan Strait,

55:58.730 --> 56:01.608
whether it's in the Ukraine,
deterring our adversaries.

56:01.691 --> 56:03.360
So, pretty excited about it.

56:03.943 --> 56:06.196
-All right. Thank you.
-So. Thank you, General.

56:06.279 --> 56:07.906
[indistinct chatter]

56:07.989 --> 56:13.370
AI pilots should be ubiquitous,
and that should be the case by 2025, 2030.

56:14.204 --> 56:17.582
Its adoption will be rapid
throughout militaries across the world.

56:17.665 --> 56:19.167
[inaudible chatter]

56:19.250 --> 56:22.962
What do you do with the Romanian military,
their UAS guy?

56:23.046 --> 56:24.756
[soldier] High-tech in the military.

56:25.256 --> 56:29.803
We've spent half a billion dollars to date
on building an AI pilot.

56:29.886 --> 56:34.015
We will spend another billion dollars
over the next five years. And that is…

56:34.099 --> 56:37.769
It's a major reason why we're winning
the programs of record in the U.S.

56:37.852 --> 56:38.853
Nice.

56:38.937 --> 56:42.732
I mean, it's impressive.
You succeeded to weaponize that.

56:43.608 --> 56:45.944
Uh, it is… This is not weaponized yet.

56:46.027 --> 56:48.321
So not yet. But yes, in the future.

56:48.905 --> 56:52.534
Our customers think about it as a truck.
We think of it as an intelligent truck

56:52.617 --> 56:54.452
that can do a lot of different things.

56:54.536 --> 56:55.703
Thank you, buddy.

56:55.787 --> 56:57.956
[Brandon] I'll make sure
to follow up with you.

56:58.456 --> 57:00.458
[inaudible chatter]

57:01.668 --> 57:04.129
If you come back in 10 years,

57:04.212 --> 57:06.256
you'll see that, um…

57:06.339 --> 57:10.802
AI and autonomy
will have dominated this entire market.

57:10.885 --> 57:12.887
[cryptic music plays]

57:14.889 --> 57:19.352
[Nathan] Forces that are supported
by AI and autonomy

57:19.436 --> 57:25.108
will absolutely dominate,
crush, and destroy forces without.

57:26.401 --> 57:30.780
It'll be the equivalent
of horses going up against tanks,

57:31.781 --> 57:34.367
people with swords
going up against the machine gun.

57:34.909 --> 57:37.120
It will not even be close.

57:38.746 --> 57:42.750
[Brandon] It will become ubiquitous,
used at every spectrum of warfare,

57:43.585 --> 57:44.836
the tactical level,

57:45.336 --> 57:46.546
the strategic level,

57:47.172 --> 57:50.800
operating at speeds
that humans cannot fathom today.

57:53.094 --> 57:57.098
[Paul] Commanders are already overwhelmed
with too much information.

57:57.599 --> 58:01.019
Imagery from satellites,
and drones, and sensors.

58:02.103 --> 58:03.396
One of the things AI can do

58:03.480 --> 58:06.774
is help a commander
more rapidly understand what is occurring.

58:07.650 --> 58:09.903
And then, "What are the decisions
I need to make?"

58:11.237 --> 58:14.866
[Bob] Artificial intelligence
will take into account all the factors

58:14.949 --> 58:17.702
that determine the way war is fought,

58:18.286 --> 58:20.246
come up with strategies…

58:22.540 --> 58:25.668
and give recommendations
on how to win a battle.

58:25.752 --> 58:27.754
[cryptic music continues]

58:27.837 --> 58:29.589
[birds chirping]

58:36.971 --> 58:40.266
[man 20] We at Lockheed Martin,
like our Department of Defense customer,

58:40.350 --> 58:43.770
view artificial intelligence
as a key technology enabler

58:43.853 --> 58:45.104
for command and control.

58:47.065 --> 58:50.235
[analyst 1] The rate of spread
has an average of two feet per second.

58:50.318 --> 58:52.695
[analyst 2] This perimeter
is roughly 700 acres.

58:52.779 --> 58:55.782
[man 20] The fog of war is
a reality for us on the defense side,

58:57.158 --> 59:00.495
but it has parallels
to being in the environment

59:00.578 --> 59:03.206
and having to make decisions
for wildfires as well.

59:03.289 --> 59:06.543
[analyst 1] The Washburn fire
is just north of the city of Wawona.

59:06.626 --> 59:09.629
[man 20] You're having to make decisions
with imperfect data.

59:10.630 --> 59:14.300
And so how do we have AI help us
with that fog of war?

59:17.637 --> 59:19.597
Wildfires are very chaotic.

59:20.181 --> 59:21.266
They're very complex,

59:22.267 --> 59:26.354
and so we're working
to utilize artificial intelligence

59:26.437 --> 59:27.855
to help make decisions.

59:28.356 --> 59:30.942
[somber melodic music plays]

59:31.442 --> 59:33.987
The Cognitive Mission Manager
is a program we're building

59:34.070 --> 59:37.949
that takes aerial infrared video

59:38.032 --> 59:41.786
and then processes it
through our AI algorithms

59:41.869 --> 59:45.248
to be able to predict
the future state of the fire.

59:45.331 --> 59:47.083
[music intensifies]

59:48.042 --> 59:49.794
[man 21] As we move into the future,

59:49.877 --> 59:52.922
the Cognitive Mission Manager
will use simulation,

59:53.006 --> 59:57.093
running scenarios
over thousands of cycles,

59:57.176 --> 01:00:00.722
to recommend the most effective way
to deploy resources

01:00:00.805 --> 01:00:04.058
to suppress high-priority areas of fire.

01:00:04.142 --> 01:00:05.810
[tense music plays]

01:00:08.062 --> 01:00:12.400
It'll say, "Go perform an aerial
suppression with a Firehawk here."

01:00:13.568 --> 01:00:15.903
"Take ground crews that clear brush…

01:00:15.987 --> 01:00:16.904
[sirens wail]

01:00:16.988 --> 01:00:19.032
…firefighters that are hosing down,

01:00:19.657 --> 01:00:23.077
and deploy them
into the highest priority areas."

01:00:24.704 --> 01:00:26.205
[music intensifies]

01:00:26.289 --> 01:00:29.292
Those decisions
will be able to be generated faster

01:00:29.375 --> 01:00:31.044
and more efficiently.

01:00:35.840 --> 01:00:38.468
[Justin T.] We view AI
as uniquely allowing our humans

01:00:38.551 --> 01:00:42.305
to be able to keep up
with the ever-changing environment.

01:00:42.388 --> 01:00:43.431
[grim music plays]

01:00:43.514 --> 01:00:46.517
And there are
a credible number of parallels

01:00:46.601 --> 01:00:50.355
to what we're used to at Lockheed Martin
on the defense side.

01:00:52.231 --> 01:00:55.860
[Emilia] The military is no longer
talking about just using AI

01:00:55.943 --> 01:01:00.323
in individual weapons systems
to make targeting and kill decisions,

01:01:00.865 --> 01:01:02.200
but integrating AI

01:01:02.283 --> 01:01:05.787
into the whole decision-making
architecture of the military.

01:01:05.870 --> 01:01:07.413
[beeping]

01:01:09.415 --> 01:01:12.960
[Bob] The Army has a big project
called Project Convergence.

01:01:14.545 --> 01:01:16.589
The Navy has Overmatch.

01:01:16.673 --> 01:01:19.592
And the Air Force has
Advanced Battle Management System.

01:01:19.676 --> 01:01:21.260
[beeping]

01:01:21.886 --> 01:01:24.138
The Department of Defense
is trying to figure out,

01:01:24.222 --> 01:01:26.683
"How do we put all these pieces together,

01:01:26.766 --> 01:01:29.268
so that we can operate
faster than our adversary

01:01:30.395 --> 01:01:32.355
and really gain an advantage?"

01:01:33.481 --> 01:01:37.527
[Stacie] An AI Battle Manager would be
like a fairly high-ranking General

01:01:37.610 --> 01:01:39.821
who's in charge of the battle.

01:01:39.904 --> 01:01:41.072
[grim music continues]

01:01:41.155 --> 01:01:44.158
Helping to give orders
to large numbers of forces,

01:01:45.118 --> 01:01:49.247
coordinating the actions
of all of the weapons that are out there,

01:01:49.330 --> 01:01:51.958
and doing it at a speed
that no human could keep up with.

01:01:52.041 --> 01:01:53.459
[music intensifies]

01:01:53.543 --> 01:01:55.294
[Emilia] We've spent the past 70 years

01:01:55.378 --> 01:01:58.798
building the most sophisticated military
on the planet,

01:01:58.881 --> 01:02:03.177
and now we're facing the decision
as to whether we want to cede control

01:02:03.261 --> 01:02:07.598
over that infrastructure to an algorithm,
to software.

01:02:08.141 --> 01:02:10.268
[indistinct chatter]

01:02:10.351 --> 01:02:13.187
And the consequences of that decision

01:02:13.271 --> 01:02:16.774
could trigger the full weight
of our military arsenals.

01:02:16.858 --> 01:02:19.902
That's not one Hiroshima. That's hundreds.

01:02:19.986 --> 01:02:21.404
[music crescendos]

01:02:25.616 --> 01:02:27.869
This is the time that we need to act

01:02:27.952 --> 01:02:33.166
because the window to actually
contain this risk is rapidly closing.

01:02:33.249 --> 01:02:34.584
[melodic music plays]

01:02:34.667 --> 01:02:39.338
[UN chair] This afternoon, we start
with international security challenges

01:02:39.422 --> 01:02:41.132
posed by emerging technologies

01:02:41.215 --> 01:02:44.343
in the area of lethal
autonomous weapons systems.

01:02:44.427 --> 01:02:47.722
[Emilia] Conversations are happening
within the United Nations

01:02:47.805 --> 01:02:50.016
about the threat
of lethal autonomous weapons

01:02:50.600 --> 01:02:56.564
and our prohibition on systems
that use AI to select and target people.

01:02:56.647 --> 01:03:00.777
Consensus amongst technologists
is clear and resounding.

01:03:00.860 --> 01:03:04.030
We are opposed
to autonomous weapons that target humans.

01:03:05.615 --> 01:03:08.993
[Izumi] For years, states have actually
discussed this issue

01:03:09.076 --> 01:03:11.329
of lethal autonomous weapon systems.

01:03:12.288 --> 01:03:16.793
This is about a common,
shared sense of security.

01:03:17.752 --> 01:03:20.546
But of course, it's not easy.

01:03:21.297 --> 01:03:25.968
Certain countries,
especially those military powers,

01:03:26.052 --> 01:03:27.762
they want to be ahead of the curve,

01:03:28.429 --> 01:03:31.599
so that they will be
ahead of their adversaries.

01:03:32.600 --> 01:03:36.187
[Paul] The problem is, everyone
has to agree to get anything done.

01:03:36.896 --> 01:03:39.065
There will be
at least one country that objects,

01:03:39.148 --> 01:03:42.109
and certainly the United States
and Russia have both made clear

01:03:42.193 --> 01:03:45.655
that they are opposed to a treaty
that would ban autonomous weapons.

01:03:47.198 --> 01:03:53.246
[Emilia] When we think about the number
of people working to make AI more powerful

01:03:54.747 --> 01:03:56.457
that room is very crowded.

01:03:57.750 --> 01:04:02.880
When we think about the room of people,
making sure that AI is safe,

01:04:04.340 --> 01:04:07.552
that room's much more sparsely populated.
[chuckles]

01:04:11.764 --> 01:04:13.724
But I'm also really optimistic.

01:04:13.808 --> 01:04:15.560
[melodic music plays]

01:04:16.060 --> 01:04:19.438
I look at something
like the Biological Weapons Convention,

01:04:19.522 --> 01:04:21.774
which happened
in the middle of the Cold War…

01:04:21.858 --> 01:04:22.942
[crowd cheers]

01:04:23.025 --> 01:04:27.655
…despite tensions between the Soviet Union
and the United States.

01:04:29.156 --> 01:04:33.536
They were able to realize
that the development of biological weapons

01:04:33.619 --> 01:04:36.247
was in neither of their best interests,

01:04:36.330 --> 01:04:38.749
and not in the best interests
of the world at large.

01:04:38.833 --> 01:04:40.835
[music intensifies]

01:04:41.335 --> 01:04:44.672
Arms race dynamics
favor speed over safety.

01:04:44.755 --> 01:04:45.631
[beeping]

01:04:45.715 --> 01:04:48.342
But I think
what's important to consider is,

01:04:48.426 --> 01:04:52.430
at some point,
the cost of moving fast becomes too high.

01:04:54.557 --> 01:04:56.142
[beeping]

01:04:56.225 --> 01:04:59.270
[Sean] We can't just develop things
in isolation

01:05:00.021 --> 01:05:06.611
and put them out there without any thought
of where they could go in the future.

01:05:07.862 --> 01:05:10.823
We've got to prevent
that atom bomb moment.

01:05:13.117 --> 01:05:14.493
[music intensifies]

01:05:14.577 --> 01:05:17.705
[Brandon] The stakes in the AI race
are massive.

01:05:18.289 --> 01:05:22.001
I don't think a lot of people
appreciate the global stability

01:05:22.084 --> 01:05:28.174
that has been provided
by having a superior military force

01:05:28.257 --> 01:05:31.135
for the past 75 years.

01:05:31.218 --> 01:05:32.803
[beeping]

01:05:32.887 --> 01:05:35.681
And so the United States
and our allied forces,

01:05:36.557 --> 01:05:38.684
they need to outperform adversarial AI.

01:05:40.436 --> 01:05:41.854
[music crescendos]

01:05:43.314 --> 01:05:44.774
There is no second place in war.

01:05:45.524 --> 01:05:47.485
[reporter 6] China laid out
an ambitious plan

01:05:47.568 --> 01:05:49.111
to be the world leader in AI by 2030.

01:05:49.195 --> 01:05:51.656
It's a race that some say America
is losing…

01:05:51.739 --> 01:05:52.657
[tense music plays]

01:05:52.740 --> 01:05:56.160
[official] He will accelerate
the adoption of artificial intelligence

01:05:56.243 --> 01:05:59.246
to ensure
our competitive military advantage.

01:05:59.330 --> 01:06:00.206
[beeping]

01:06:00.289 --> 01:06:02.291
[music intensifies]

01:06:02.875 --> 01:06:05.461
[Paul] We are racing forward
with this technology.

01:06:05.544 --> 01:06:08.673
I think what's unclear
is how far are we going to go?

01:06:09.507 --> 01:06:12.760
Do we control technology,
or does it control us?

01:06:14.136 --> 01:06:16.973
[Emilia] There's really no opportunity
for do-overs.

01:06:17.807 --> 01:06:20.977
Once the genie is out of the bottle,
it is out.

01:06:22.019 --> 01:06:25.189
And it is very, very difficult
to put it back in.

01:06:26.065 --> 01:06:27.566
[beeping]

01:06:28.609 --> 01:06:31.737
[Sean] And if we don't act now,
it's too late.

01:06:31.821 --> 01:06:33.030
[beeping]

01:06:33.114 --> 01:06:34.657
It may already be too late.

01:06:35.366 --> 01:06:36.200
[beeping]

01:06:42.123 --> 01:06:43.499
[music crescendos]

01:06:45.209 --> 01:06:48.212
[somber melodic music plays]

01:08:53.629 --> 01:08:57.383
[harmonic tones chime]
